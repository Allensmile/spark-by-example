#+EXPORT_FILE_NAME: ../../../heap/Pop_Heap.org
#+OPTIONS: author:nil title:nil toc:nil
** The Pop_Heap algorithm

The ~Pop_Heap~ procedure will remove the root (and greatest) element of the heap, and rearange the other elements to preserve the heap structure.
Its signature reads:

#+BEGIN_SRC ada 
procedure Pop_Heap(H : in out Heap)
#+END_SRC

*** Specififcation of Pop_Heap

We now give a more precise definition of what this procedure should do. ~Pop_Heap~ will remove the first element of the heap,
rearange the ~H.Size-1~ remaining elements so that the heap structure is preserved on those elements, which will then occupy the ~H.Size-1~ indexes of the array.
The procedure will then reinsert the removed element at index ~H.Size~, which was no longer used. 

With these considerations in mind, one specification for ~Pop_Heap~ is:

	#+INCLUDE: ../../../heap/pop_heap_p.ads :src ada :range-begin "procedure Pop_Heap" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "25-37"

The preconditions state that in order to remove an element from the heap, thisone must not be empty, and the record of type ~Heap~ 
we will be working on must represent a heap data structure.
the postconditions express that:
- The number of occurences of each element of ~T~ in ~H~ will not have change when calling the procedure
- The size of the elements in the heap data structure will be one less than when entering the procedure
- ~H~ will still represent a heap data structure containing the remaining elements.
- The first element of ~H.A~ will be place at index ~H.Size+1~, bearing in mind that ~H.Size~ has been decreased by one during the procedure.
- The elementas found at indexes greater than ~H'Old.Size~ will remain unchanged.
- The element found at index ~H.Size+1~ after the procedure will be the greatest element amond the ~H.Size+1~ first elements of ~H~.

*** Predicates and lemmas used
    
In order to correctly specify and implement ~Pop_Heap~ we need to write a few lemmas and predicates.

**** The Max_Element_Def predicate

This predicate defines if a given index corrrespnds to the maximum element of a given array:

	#+INCLUDE: ../../../spec/upper_bound_p.ads :src ada :range-begin "function Max_Element_Def" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "16-20"

**** The predicate Heap_Maximum_Child

	#+INCLUDE: ../../../spec/heap_predicates.ads :src ada :range-begin "function Heap_Maximum_Child" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "23-35"


This predicates verifies for a given ~Heap~ record and two indexes ~P~ and ~C~ that:
- ~H~ represents a heap data structure
- There are at least two elements in the heap represented by ~H~
- ~P~ can be a parent, i.e. is in the correct range, and cannot be the last element of the heap,
- at least one of the children of ~P~ is in the heap (~P <= H.Size/2~) , and then ~C~ must be a child of ~P~, and the value at index ~C~ must be the greatest of the two values found at the indexes of the children of ~P~

**** The Maximum_Heap_Child function

This function returns an option containing, for a given heap ~H~ and a given index ~P~, the child of P for which the associated value is the greatest if it exists in the heap.

Its specification is as follows:

	#+INCLUDE: ../../../heap/pop_heap_p.ads :src ada :range-begin "function Maximum_Heap_Child" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "13-24"

The preconditions express that ~H~ represents a heap data structure, the heap represented by ~H~ has at least two elements and that ~P~ is a valid parent index.
The postconditions are expressed through contract cases:
- if the children of ~P~ are not represented in ~H~, then there is nothing returned
- Otherwise the returned value complies with the definitions of the maximum child, given by the previous predicate.


This function can be implemented in the following way:

	#+INCLUDE: ../../../heap/pop_heap_p.adb :src ada :range-begin "function Maximum_Heap_Child" :range-end "End Maximum_Heap_Child;" :lines "4-22"

The implementation is quite strainghtforward, as there are no loops or calls to other function, the program does not need annotations to be proved.

**** Heap lemmas

We present here two lemmas concerning the properties of heap when modifying an element or concerning the order of the elements.

	#+INCLUDE: ../../../lemmas/pop_heap_lemmas.ads :src ada :range-begin "procedure Heap_Set" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "13-22"
	#+INCLUDE: ../../../lemmas/pop_heap_lemmas.ads :src ada :range-begin "procedure Upper_Bound_Heap" :range-end "\s-*(\(.*?\(?:\n.*\)*?\)*)\s-*\([^;]*?\(?:\n[^;]*\)*?\)*;" :lines "23-26"

In this lemma we prove that replacing the value at index ~P~ in a heap by the value found at the maximum child of ~P~ does not change the heap properties.
More specificaly here the preconditions, which act as hyposthesis ewpress that:
- Our two heaps must be of same size,
- ~C~ is the child of greatest value of ~P~
- ~H1~ verifies all the properties of a heap
- ~H2~ is equal to ~H1~ to the exception of the index ~P~ which is equal to ~H1.A(C)~.

The postcondition express the fact that if these hypothesis are respected then ~H2~ also respect the properties defining a heap.

The body of the procedure only consists of the instruction ~null;~, as guiding Spark by giving him the rigth hypothesis to work with is enough for him to prove the lemma.

	#+INCLUDE: ../../../lemmas/pop_heap_lemmas.adb :src ada :range-begin "procedure Heap_Set" :range-end "End Heap_Set;" :lines "4-8"
	#+INCLUDE: ../../../lemmas/pop_heap_lemmas.adb :src ada :range-begin "procedure Upper_Bound_Heap" :range-end "End Upper_Bound_Heap;" :lines "9-13"

This lemma is here to make the solvers aware that if ~H~ respects the heap properties, and if ~V~ is 
greater than the first element of ~H~ then ~V~ is greater than all the others elements of ~H~. This can be proved by induction
with the relations betwen parents and children, but spark can prove this lemma automatically, so the body of the procedure only consits of the ~null;~ instruction.

When proving ~Upper_Bound_Heap~ spark issues a warning:

#+BEGIN_SRC ada
heap_lemmas.ads:27:06: warning: postcondition does not check the outcome of calling "Upper_Bound_Heap"
#+END_SRC

This is a know issue of the developpers of Spark, we will supress this warning the same way it is done in the [[https://github.com/AdaCore/spark2014/blob/master/include/spark-constrained_array_lemmas.ads][SPARK Lemma Library]], by adding the following instruction in the package containing the lemmas:

#+BEGIN_SRC ada
pragma warnings
     (off, "postcondition does not check the outcome of calling");
#+END_SRC

*** Implementation of Pop_Heap

With all these lemmas and predicates we can give an implementation for ~Pop_Heap~

	#+INCLUDE: ../../../heap/pop_heap_p.adb :src ada :range-begin "procedure Pop_Heap" :range-end "End Pop_Heap;" :lines "23-182"

The code with all the annotations is quite difficult to read, it might be better to look at the code without annotations to understand the working principle of this algorithm:

#+BEGIN_SRC ada
procedure Pop_Heap(H : in out Heap) 
   is
      V : T := H.A(1);
      Hole : Positive := 1;
      Child : Option;
   begin
      if H.A(H.Size) < V then  --nothing to be done otherwise (array is "constant")
         Child := Maximum_Heap_Child(H,Hole);
         if Child.Exists then
            C1 := Child.Value;
         else
            C1 := H.Size+1;
         end if;

         while Child.Exists and then Child.Value < H.Size and then  H.A(H.Size) < H.A(Child.Value) loop
            
            H.A(Hole) := H.A(Child.Value); 
	    Hole := Child.Value;
            Child := Maximum_Heap_Child(H,Hole);
            
         end loop;
         
         H.A(Hole) := H.A(H.Size);
         H.A(H.Size) := V;
      
      end if;
      H.Size := H.Size-1;
      
   end Pop_Heap;
#+END_SRC

Here the idea behing the procedure is to remove the first element, thus creating a "hole" in the heap. We then proceed to move the hole down the heap wile taking care to preserve the heap structure, until it reaches the en of the heap, where we reinsert the removed value. More specificaly the procedure is as follows:
1. We store the first value of the heap (which will be removed). We now consider that there is a "Hole" in the heap, that needs to go down, while preserving the heap structure.
2. we find the child of maximum value of the hole, and we exchange them. This guarantees that the heap structure is preserved. This step is repeated as many times as needed, until the value of the next child is less than the value of the last element
3. when exiting the loop, the hole is replaced by the last element of the heap. We then consider that the heap has only ~H.Size-1~ elements, and the element removed at the begining of the algorithm is placed at the index ~H.Size~.

As for the annotations to help SPARK prove the program, we will first need a few ghost variables:
- ~C1~, which will hold the maximum Child of the first element. It will come in handy when proving that the first element of H remains constant through the loop
- ~Sizes~ which will simply hold the size of ~H~. It will be used to fix ann issue of array index check.
- ~Interm~ This variable will be used to compare the approcah of swapping the elements at indexes ~Hole~ and ~Child.Value~, which acts as a permutation, instead of simply replacing the value of the hole by the one of it's child, which preserves the heap structure.
- ~Init~ which as it's name suggests holds the state of ~H~ before the execution of the algorithm
- ~Save~ which will be used as a temporary save to compare the state of the heap between various points of the Algorithm.


The implementation is rich in asssertions, most of them help verify the preconditions to the lemmas and predicates we will use. The following section will nevertheless explain the thought process
behind the annotation of the program:

The first thing to notice is that the working principle of the algorithm is quite similar to [[Push_Heap.org][Push_Heap]], so we could have taken the same approach
to prove the postcondition ~Multiset_Unchanged(H'Old.A,A)~ with the help of the predicates ~Multiset_Add~ and ~Multiset_Minus~. This approach was necessary because when moving the "hole" around the number of occurences
varies but the structure of heap is preserved. Here to prove this postcondition we will duplicate the array at the begining, and at each iteration we will swap the values found at indexes ~Child.Value~ and ~Hole~. This approach does not preserve the structure of heap, but verifies that
only permutations are applied to the array. 

Let's take a look at the ~while~ loop. We first save the state of ~H~ in order to be able to help the solvers assess the changes that will occur during the loop. We then swap the values at indexes ~Hole~ and ~Child.Value~ for ~Interm~
and replace the value found at index ~Hole~ by the one found at ~Child.Value~. As mentionned before, the "swap" approach aims to prove the ~multiset_unchanged~ postcondition. The ~swap prcedure ensures this through it's postconditions, so there is no need to annotate this part of the code.
On the other hand when simply replacing the value found at the index ~Hole~, SPARK does not manage to prove that the heap structure is preserved. That is why we then proced to call the lemma ~Heap_Set~. All the preceeding assertions are hrer to verify the hypothesis to the lemma. Now that
we know that ~H~ is still a heap, we can use the order properties of the heap data structure in order to proove that the element removed at the begining of the procedure is an upper bound for the heap. This is done by calling the lemma ~Upper_Bound_Heap~. With these two lemmas 
instanciated we have everything we need in order to prove the loop invariants.

The loop invariants (in order of appearance) ensure that: 
1) All the values found at indexes greater than ~H.Size~ remain unchanged
2) The first element of the heap remains constant after the first swap. This is useful to prove that the element we removed is greater than all the elements left in the heap
3) The loop invariants 3 to 10 check that various preconditions to the predicates used later hold true *at this point* in the loop
4) ~V~ is an upperbound for the remaining elements in the Heap. It should be noted that in the call to ~Upper_Bound~ we use ~Sizes~ and not ~H.Size~ (which are equal in value throughout the loop) to avoid an an ~range check might fail~ error from GNATprove.
5) ~Interm~ is a permutation of the initial array
6) ~Interm~ is equal to ~H.A~ to the exception of index ~Child.Value~, which is equal to ~V~. This loop invariant helps the solvers keep track of the differences between ~Interm~ and ~H.A~
7) ~H~ has a heap structure

The only remaining thing left in the loop is the update of ~Child~ and of ~Hole~. Since we use a ~while~ loop we need to specify that ~Child.Value~ decreases as a loop variant.

After exiting the loop, we are left with three variable assignments, and yet without annotating them the proof of the postconditions is impossible. The reason behind this issue is that there are multiple causes for exiting the wile loop,
and the exit conditions have non trivial implications on the values of ~Hole~, ~Child~ and the state of the heap. We will detail what the exit conditions are, what they implicate and the annotations that were added to help the solvers understand
what is going on. When exiting the loop, ~Child~ is the ~Maximum_Heap_Child~ of ~Hole~. One thing that is alwas true when exiting the loop is that ~H.A(Hole) > H.A(H.Size)~ (otherwise, the loop would have exited in the previous iteration). This ensures that when executing ~H.A(Hole) := H.A(H.Size)~ the heap structure is preserved.
The case when we exit the loop with ~Child.Exists~ equal to ~False~ corresponds to the case where the "hole" has no children. The solvers can keep track of what is happening, so there is no need to add any assertions. When we exit the loop with ~Child.Exists = True~ and ~Child.Value = H.Size~ then
the affectation acts as if we did one more iteration of the loop, so there is nothing to add here, but when we exit the loop with
~Child.Exists = True~, ~Child.Value < H.Size~, then ~H.A(Child.Value) <= H.A(H.Size)~. In that case the solvers need a bit of guidance to understand that replacing the value found at ~Hole~ by the one found at ~H.Size~ will preserve the heap structure. This is due to the fact that the automatic proof does not remember that in the
previous iteration, the parent of ~Hole~ had a value strictly greater than the value found at ~H.Size~. This is corrected with the assertion right after the loop

We then proceed to replace the value found at index ~Hole~, the two following assertions help prove the conservation of the heap structure. We then proceed to replace the value found at index ~H.Size~ by the value saved at the begining of the algorithm, and to swap the values found at indexes ~Hole~ and ~H.Size~ in ~Interm~, which is equivalent to the two previous affectations donne in ~H.A~.
We check that the other indexes were not modified, and this concludes the modifications that will be donne to the arrays. 

The "else" case of the main condition verifies that if we do not have ~H.A(1) > H.A(H.Size)~ at the begining of the algorithm, then ~H.A(1) = H.A(H.Size))~. (This is true, because wi the properties of a heap we can demonstrate that the array is constant)

What is left to check is that our two approaches (swaping and replacing) give the same end result, and with a similar technique used in the proof of [[../mutating/Random_Shuffle.org][Swap_Array]] we prove the ~multiset_unchaged~ postcondition. The last few annotations verify the ~Max_Element~ postcondition.

This concludes our implementation of ~Pop_Heap~. This implementation is completly proved by ~GNATprove~, but requires the use of a high level of proof (level 4) and requires 5 minutes of pooving time, due to the amout of verification conditions being generated by GNATprove.
